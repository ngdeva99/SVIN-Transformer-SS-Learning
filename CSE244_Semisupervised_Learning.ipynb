{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Extract the Dataset"
      ],
      "metadata": {
        "id": "hn7_T72D9bZh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/ucsc-cse-244-a_data-set.zip -d /content/data-set/"
      ],
      "metadata": {
        "id": "9-JuRwWz_rPB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import Dependencies"
      ],
      "metadata": {
        "id": "o9XOgvRu9hTB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install timm\n",
        "!pip install tqdm"
      ],
      "metadata": {
        "id": "z84BCzaqDZzK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4scITVp1rv_L"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "from torchvision import models, transforms\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader, Subset\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.model_selection import KFold\n",
        "from tqdm import tqdm\n",
        "from torch.utils.data import random_split\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "import shutil\n",
        "import timm"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Auxiliary code"
      ],
      "metadata": {
        "id": "rgL_dMGZygy_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F3db-1YFrv_M"
      },
      "outputs": [],
      "source": [
        "# Custom dataset class\n",
        "class ImageDataset(Dataset):\n",
        "    def __init__(self, image_folder, csv_file, transform=None):\n",
        "        self.image_folder = image_folder\n",
        "        self.labels_df = pd.read_csv(csv_file)\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels_df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_name = os.path.join(self.image_folder, self.labels_df.iloc[idx, 0])\n",
        "        label = int(self.labels_df.iloc[idx, 1])\n",
        "        image = Image.open(img_name).convert(\"RGB\")\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9rLQgio7rv_M"
      },
      "outputs": [],
      "source": [
        "# Paths\n",
        "labeled_image_folder = \"/content/data-set/train/labeled\"\n",
        "labeled_image_true_values = \"/content/data-set/train_labeled.csv\"\n",
        "\n",
        "unlabeled_image_folder = '/content/data-set/train/unlabeled'\n",
        "combined_image_folder = '/content/data-set/train/combined-swin-128'\n",
        "\n",
        "combined_csv_path = '/content/data-set/train/combined_labels-conf95-swin-noaug-128.csv'"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model training on labeled data"
      ],
      "metadata": {
        "id": "5KgI9zX7y6gA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SKXSpBZ_rv_M"
      },
      "outputs": [],
      "source": [
        "# Image transforms\n",
        "transform_swin = transforms.Compose([\n",
        "    transforms.Resize((384, 384)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4ETR8JR6rv_M",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "outputId": "250507ba-9d81-44a8-b262-5f0c33adf3de"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/data-set/train_labeled.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-acf655f3757b>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Dataset and DataLoader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImageDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabeled_image_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabeled_image_true_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransform_swin\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdataloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-824c67ecab90>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, image_folder, csv_file, transform)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcsv_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_folder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage_folder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcsv_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    946\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 948\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 611\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1447\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1448\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1450\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1703\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1704\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1705\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1706\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1707\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    861\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    862\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 863\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    864\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    865\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/data-set/train_labeled.csv'"
          ]
        }
      ],
      "source": [
        "# Dataset and DataLoader\n",
        "dataset = ImageDataset(labeled_image_folder, labeled_image_true_values, transform=transform_swin)\n",
        "dataloader = DataLoader(dataset, batch_size=64, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y7ZadtTkrv_N",
        "outputId": "dbb6bd4d-0e67-4b35-fb95-81a75937e77d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153,
          "referenced_widgets": [
            "edfc4812cd6242929a5433e7731c46b1",
            "c50985fdddab41508f47f699cea57037",
            "434d8e66323143478478bda6ae89e55c",
            "f1019ab57b7a4dca841097afc0b4a73a",
            "6abb5abb962f42fba057357c756daef9",
            "038136ab1a3f438892c2e6e0653b7e0b",
            "2f5cf0cbcbb9496396ee2cb6ccc3ef05",
            "d74ad149740d4ed1be92ff373cfd28fe",
            "b474d5394c0545939a1ddfe9392d6f20",
            "d620f793c980479aa1ebf8086f462c45",
            "c0ece548205f476fa7202472ef11e74b"
          ]
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/801M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "edfc4812cd6242929a5433e7731c46b1"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "model = timm.create_model('swin_large_patch4_window12_384', pretrained=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wCVN5hQlrv_N"
      },
      "outputs": [],
      "source": [
        "# Freeze the feature extractors\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# Unfreeze the classification head\n",
        "for param in model.head.parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "# Unfreeze the last block in the last stage\n",
        "for param in model.layers[3].blocks[1].parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "# Unfreeze the last block in the last stage\n",
        "for param in model.layers[3].blocks[0].parameters():\n",
        "    param.requires_grad = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-0uFrs5jrv_N"
      },
      "outputs": [],
      "source": [
        "# Update the classification head\n",
        "num_classes = 135  # Example: Change to the number of classes in your dataset\n",
        "model.head.fc = nn.Linear(model.head.fc.in_features, num_classes)\n",
        "\n",
        "# Move model to GPU if available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "\n",
        "# Define optimizer and loss function\n",
        "optimizer = torch.optim.AdamW([\n",
        "    {'params': model.head.fc.parameters(), 'lr': 1e-3},  # Higher LR for the head\n",
        "    {'params': model.layers[3].blocks[0].parameters(), 'lr': 5e-5},  # Lower LR for the last block\n",
        "    {'params': model.layers[3].blocks[1].parameters(), 'lr': 1e-4},  # Lower LR for the last block\n",
        "], weight_decay=1e-4)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Define learning rate scheduler based on training loss\n",
        "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=10, eta_min=1e-6)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FYzuv8k-rv_O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c79837c-1e0f-4e1a-8c2a-946913d7cc3e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/15: 100%|██████████| 308/308 [09:09<00:00,  1.78s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15, Loss: 0.6611088843314679\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/15: 100%|██████████| 308/308 [09:07<00:00,  1.78s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/15, Loss: 0.11903083149733797\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/15: 100%|██████████| 308/308 [09:05<00:00,  1.77s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/15, Loss: 0.05580148684290274\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/15: 100%|██████████| 308/308 [09:05<00:00,  1.77s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/15, Loss: 0.028244254820528076\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/15: 100%|██████████| 308/308 [09:05<00:00,  1.77s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/15, Loss: 0.020848703780532784\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6/15: 100%|██████████| 308/308 [09:07<00:00,  1.78s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6/15, Loss: 0.012520563044438257\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7/15: 100%|██████████| 308/308 [09:07<00:00,  1.78s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7/15, Loss: 0.009994726994650533\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8/15: 100%|██████████| 308/308 [09:09<00:00,  1.78s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8/15, Loss: 0.007387970265326303\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9/15: 100%|██████████| 308/308 [09:10<00:00,  1.79s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9/15, Loss: 0.007090803820869656\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10/15: 100%|██████████| 308/308 [09:08<00:00,  1.78s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/15, Loss: 0.00683605933831982\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 11/15: 100%|██████████| 308/308 [09:09<00:00,  1.78s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11/15, Loss: 0.005412228829229278\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 12/15: 100%|██████████| 308/308 [09:09<00:00,  1.78s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12/15, Loss: 0.005635500421774779\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 13/15: 100%|██████████| 308/308 [09:08<00:00,  1.78s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13/15, Loss: 0.005583871227555663\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 14/15: 100%|██████████| 308/308 [09:08<00:00,  1.78s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14/15, Loss: 0.006561699341380683\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 15/15: 100%|██████████| 308/308 [09:08<00:00,  1.78s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15/15, Loss: 0.011315035485577855\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Training loop\n",
        "epochs = 15\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "\n",
        "    for images, labels in tqdm(dataloader, desc=f\"Epoch {epoch+1}/{epochs}\", leave=True):\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        # Zero the gradient\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "\n",
        "        # Compute loss and backpropagate\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "\n",
        "        # Update weights\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    avg_train_loss = running_loss/len(dataloader)\n",
        "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {avg_train_loss}\")\n",
        "    scheduler.step()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3WfJY3Xlrv_O"
      },
      "outputs": [],
      "source": [
        "model_save_path = '/content/swin_large_32.pth'\n",
        "\n",
        "# Save the model state_dict\n",
        "torch.save(model.state_dict(), model_save_path)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_images_folder = './data-set/test'\n",
        "test_images = os.listdir(test_images_folder)\n",
        "\n",
        "# # Move the model to the desired device (GPU or CPU)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "# Initialize lists for pseudo-labels\n",
        "pseudo_labels = []\n",
        "predictions = []\n",
        "\n",
        "# Set the model to evaluation mode (useful for inference)\n",
        "model.eval()\n",
        "# count = 0\n",
        "with torch.no_grad():\n",
        "    for img_name in tqdm(test_images, desc=\"Labeling images\", unit=\"image\"):\n",
        "        img_path = os.path.join(test_images_folder, img_name)\n",
        "        image = Image.open(img_path).convert(\"RGB\")\n",
        "        image = transform_swin(image).unsqueeze(0).to(device)  # Add batch dimension\n",
        "\n",
        "        outputs = model(image)  # Get model outputs\n",
        "        prob = torch.softmax(outputs, dim=1)  # Convert to probabilities\n",
        "        confidence, predicted = torch.max(prob, 1)\n",
        "\n",
        "        predictions.append(predicted.item())\n",
        "        pseudo_labels.append(img_name)  # Collect pseudo-labels\n",
        "\n",
        "# Create a DataFrame for pseudo-labels\n",
        "df_pseudo = pd.DataFrame({'image': pseudo_labels, 'id': predictions})\n",
        "\n",
        "print(df_pseudo)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U4ZXYJF3kqZv",
        "outputId": "ce282530-b5cf-4242-e5bc-d29fd9ef6dd7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Labeling images: 100%|██████████| 8213/8213 [07:38<00:00, 17.91image/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "          image  id\n",
            "0     37974.jpg  65\n",
            "1     33618.jpg   4\n",
            "2     36143.jpg   8\n",
            "3     35001.jpg   7\n",
            "4     37044.jpg   7\n",
            "...         ...  ..\n",
            "8208  37142.jpg   6\n",
            "8209  36486.jpg   8\n",
            "8210  33912.jpg   9\n",
            "8211  39932.jpg  14\n",
            "8212  40686.jpg  47\n",
            "\n",
            "[8213 rows x 2 columns]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_pseudo.to_csv('/content/final_prediction_swinlarge_32.csv', index=False)"
      ],
      "metadata": {
        "id": "TC-uw7bqlCCi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Semi-supervised learning"
      ],
      "metadata": {
        "id": "lJd8rfj-y_er"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "confidence_threshold = 0.95"
      ],
      "metadata": {
        "id": "599C6o8Ds7sg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unlabeled_images = os.listdir(unlabeled_image_folder)\n",
        "swin_model_load_path = './saved-models/swin_sched_noaug_128.pth'\n",
        "\n",
        "# Define the model architecture (same as the one used during training)\n",
        "num_classes = 135  # Example: Change to the number of classes in your dataset\n",
        "model = timm.create_model('swin_base_patch4_window7_224', pretrained=True) # Set pretrained=False for custom weights\n",
        "model.head.fc = nn.Linear(model.head.fc.in_features, num_classes)\n",
        "\n",
        "# Load the model state_dict from a .pth file\n",
        "model.load_state_dict(torch.load(swin_model_load_path))\n",
        "\n",
        "# Move the model to the desired device (GPU or CPU)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "\n",
        "# Initialize lists for pseudo-labels\n",
        "image_names = []\n",
        "pseudo_labels = []\n",
        "\n",
        "# Set the model to evaluation mode (useful for inference)\n",
        "model.eval()\n",
        "\n",
        "with torch.no_grad():\n",
        "    for img_name in tqdm(unlabeled_images, desc=\"Labeling images\", unit=\"image\"):\n",
        "        img_path = os.path.join(unlabeled_image_folder, img_name)\n",
        "        image = Image.open(img_path).convert(\"RGB\")\n",
        "        image = transform_swin(image).unsqueeze(0).to(device)  # Add batch dimension\n",
        "\n",
        "        outputs = model(image)  # Get model outputs\n",
        "        prob = torch.softmax(outputs, dim=1)  # Convert to probabilities\n",
        "        confidence, predicted = torch.max(prob, 1)\n",
        "\n",
        "        # Apply confidence threshold (e.g., 0.95)\n",
        "        if confidence.item() > confidence_threshold:\n",
        "            image_names.append(predicted.item())\n",
        "            pseudo_labels.append(img_name)  # Collect pseudo-labels\n",
        "\n",
        "# Create a DataFrame for pseudo-labels\n",
        "df_pseudo = pd.DataFrame({'image': pseudo_labels, 'id': image_names})\n",
        "\n",
        "print(df_pseudo)"
      ],
      "metadata": {
        "id": "rZdqH8Umserw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labeled_csv_path = './data-set/train_labeled.csv'  # Path to labeled CSV\n",
        "pseudo_labels_csv_path = './data-set/train/unlabeled-prediction-noaug-swin-128.csv'  # Path to pseudo-labeled CSV\n",
        "\n",
        "# Create the combined image folder if it doesn't exist\n",
        "os.makedirs(combined_image_folder, exist_ok=True)\n",
        "\n",
        "# Load labeled data\n",
        "labeled_df = pd.read_csv(labeled_csv_path)\n",
        "# Load pseudo-labeled data\n",
        "pseudo_labels_df = pd.read_csv(pseudo_labels_csv_path)\n",
        "\n",
        "# Step 3: Copy labeled images to the combined folder\n",
        "for _, row in labeled_df.iterrows():\n",
        "    img_name = row['image']  # Use 'image' to get the filename from labeled data\n",
        "    src_path = os.path.join(labeled_image_folder, img_name)\n",
        "    dst_path = os.path.join(combined_image_folder, img_name)\n",
        "    shutil.copy(src_path, dst_path)\n",
        "\n",
        "# Step 4: Copy pseudo-labeled images to the combined folder\n",
        "for _, row in pseudo_labels_df.iterrows():\n",
        "    img_name = row['image']  # Use 'image' to get the filename from pseudo-labeled data\n",
        "    src_path = os.path.join(unlabeled_image_folder, img_name)\n",
        "    dst_path = os.path.join(combined_image_folder, img_name)\n",
        "    shutil.copy(src_path, dst_path)\n",
        "\n",
        "# Step 5: Combine DataFrames\n",
        "# Create a DataFrame for the combined data\n",
        "combined_df = labeled_df.copy()\n",
        "\n",
        "# Rename the columns in the pseudo_labels_df to match the labeled_df\n",
        "pseudo_labels_df = pseudo_labels_df.rename(columns={'filename': 'image', 'label': 'id'})  # Rename columns\n",
        "\n",
        "# Append pseudo-labeled data\n",
        "combined_df = pd.concat([combined_df, pseudo_labels_df], ignore_index=True)\n",
        "\n",
        "# Save the combined DataFrame to a new CSV\n",
        "# combined_csv_path = './data-set/train/combined_labels-conf95-swin-noaug-128.csv'\n",
        "combined_df.to_csv(combined_csv_path, index=False)\n",
        "\n",
        "print(f'Combined dataset created at {combined_image_folder}')\n",
        "print(f'Combined labels saved to {combined_csv_path}')"
      ],
      "metadata": {
        "id": "_fyezZydsgQE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r model_weights.zip swin_large_32.pth"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mGIy6-40pl9A",
        "outputId": "1cefc4b6-7681-410b-c9ae-7b0e52d5feff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: swin_large_32.pth (deflated 7%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Retraining the combined Dataset (Labelled + Unlabbeled)"
      ],
      "metadata": {
        "id": "HiE1OPXR-ZKm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Combined Image Generator"
      ],
      "metadata": {
        "id": "vfZxEXng-jMd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Custom dataset class\n",
        "class ImageDataset(Dataset):\n",
        "    def __init__(self, image_folder, csv_file, transform=None):\n",
        "        self.image_folder = image_folder\n",
        "        self.labels_df = pd.read_csv(csv_file)\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels_df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_name = os.path.join(self.image_folder, self.labels_df.iloc[idx, 0])\n",
        "        label = int(self.labels_df.iloc[idx, 1])\n",
        "        image = Image.open(img_name).convert(\"RGB\")\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image, label\n",
        "\n",
        "\n",
        "# Load datasets\n",
        "combined_csv_path = '/content/combined_labels.csv'\n"
      ],
      "metadata": {
        "id": "S4MfDYry-hGF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Transforms (w/ or w/o Augumentation)"
      ],
      "metadata": {
        "id": "yqRnqlZD-uy3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Image transforms\n",
        "transform_swin = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])"
      ],
      "metadata": {
        "id": "SdRUFeeT-thM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Definiton + Training"
      ],
      "metadata": {
        "id": "sMCe1GsO-7q-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create dataset and data loader\n",
        "combined_dataset = ImageDataset(combined_image_folder, combined_csv_path, transform=transform_swin)\n",
        "\n",
        "# Split the dataset into training (80%) and validation (20%)\n",
        "train_size = int(0.8 * len(combined_dataset))\n",
        "val_size = len(combined_dataset) - train_size\n",
        "train_dataset, val_dataset = random_split(combined_dataset, [train_size, val_size])\n",
        "\n",
        "# Create DataLoaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "# Initialize your model\n",
        "model = timm.create_model('swin_base_patch4_window7_224', pretrained=True)\n",
        "\n",
        "\n",
        "# Freeze the feature extractors\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# Unfreeze the classification head\n",
        "for param in model.head.parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "# Unfreeze the nth block in the last stage\n",
        "for param in model.layers[3].blocks[1].parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "# Unfreeze the n-1th block in the last stage\n",
        "for param in model.layers[3].blocks[0].parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "# Update the classification head\n",
        "num_classes = 135  # Example: Change to the number of classes in your dataset\n",
        "model.head.fc = nn.Linear(model.head.fc.in_features, num_classes)\n",
        "\n",
        "# Define optimizer and loss function\n",
        "optimizer = torch.optim.AdamW([\n",
        "    {'params': model.head.fc.parameters(), 'lr': 1e-3},  # Higher LR for the head\n",
        "    {'params': model.layers[3].blocks[0].parameters(), 'lr': 1e-4},  # Lower LR for the last block\n",
        "    {'params': model.layers[3].blocks[1].parameters(), 'lr': 5e-4},  # Lower LR for the last block\n",
        "], weight_decay=1e-4)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Define learning rate scheduler based on training loss\n",
        "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=10, eta_min=1e-6)"
      ],
      "metadata": {
        "id": "HktsWZt3-7G6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Training"
      ],
      "metadata": {
        "id": "e_1bm90p_DqA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize lists to store validation loss and accuracy\n",
        "val_losses = []\n",
        "val_accuracies = []\n",
        "\n",
        "# Training loop with validation\n",
        "epochs = 5  # Adjust the number of epochs as needed\n",
        "for epoch in range(epochs):\n",
        "    # Training phase\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "\n",
        "    for images, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\", leave=True):\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        # logits = outputs.logits\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{epochs}, Training Loss: {running_loss / len(train_loader):.4f}\")\n",
        "\n",
        "    # Validation phase\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in val_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            # logits = outputs.logits\n",
        "            loss = criterion(outputs, labels)  # Calculate validation loss\n",
        "            val_loss += loss.item()  # Accumulate validation loss\n",
        "            _, predicted = torch.max(outputs, 1)  # Get predicted classes\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    accuracy = correct / total\n",
        "    val_losses.append(val_loss / len(val_loader))  # Store average validation loss\n",
        "    val_accuracies.append(accuracy * 100)  # Store validation accuracy in percentage\n",
        "\n",
        "    print(f'Validation Loss: {val_loss / len(val_loader):.4f}, Validation Accuracy: {accuracy * 100:.2f}%')\n",
        "    #Model Name\n",
        "    modelName = 'CUSTOM_MODEL_NAME'\n",
        "    torch.save(model.state_dict(), f'/content/{modelName}-{epoch+1}.pth')"
      ],
      "metadata": {
        "id": "d97QjU8n_Fwn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plot Generation"
      ],
      "metadata": {
        "id": "wlPtyP8t_Gra"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting validation loss and accuracy\n",
        "plt.figure(figsize=(12, 5))\n",
        "\n",
        "# Plot validation loss\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(range(1, epochs + 1), val_losses, marker='o', label='Validation Loss', color='blue')\n",
        "plt.title('Validation Loss Over Epochs')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.xticks(range(1, epochs + 1))\n",
        "plt.grid()\n",
        "plt.legend()\n",
        "\n",
        "# Plot validation accuracy\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(range(1, epochs + 1), val_accuracies, marker='o', label='Validation Accuracy', color='green')\n",
        "plt.title('Validation Accuracy Over Epochs')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy (%)')\n",
        "plt.xticks(range(1, epochs + 1))\n",
        "plt.grid()\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "t06EpxNoAk42"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testing"
      ],
      "metadata": {
        "id": "PFwRG7xdA8_C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_images_folder = '/content/test'\n",
        "test_images = os.listdir(test_images_folder)\n",
        "\n",
        "model = timm.create_model('swin_base_patch4_window7_224', pretrained=True)"
      ],
      "metadata": {
        "id": "zhpRW-kCdQyo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153,
          "referenced_widgets": [
            "ddd97f1ce7644d818c70cb16eddf1c42",
            "0a447e9732d043989b61444fb8699feb",
            "cd269129df5e4984b6acb1ad54f46b8e",
            "63eb77a3abd04829834fac9fb54942b1",
            "afd9a91766434e97ae67e26103fac61d",
            "408542b8f5934fee9634064134c7a32f",
            "0c423977e1124645ae692c5a2804bb12",
            "1d100248fc1842c28da2c0498726e044",
            "46957bea35ed4d7e937f3d8208cfd566",
            "0bcd0d1944bd418693ce7c0abe710ff9",
            "7b09fbb3561f4841a981e8af628a565b"
          ]
        },
        "outputId": "0671011a-f78f-40b7-b82f-bec461662ffd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/353M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ddd97f1ce7644d818c70cb16eddf1c42"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Update the classification head\n",
        "num_classes = 135  # Example: Change to the number of classes in your dataset\n",
        "model.head.fc = nn.Linear(model.head.fc.in_features, num_classes)\n",
        "\n",
        "model.load_state_dict(torch.load('/content/drive/Shareddrives/CSE244A/swin_combined-b64-e15-aug-epoch_21.pth'))"
      ],
      "metadata": {
        "id": "h3DlG4Hkdd79",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e7d0d35-47e0-462a-9c11-52f2f0295731"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-c6466fc8d2b8>:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load('/content/drive/Shareddrives/CSE244A/swin_combined-b64-e15-aug-epoch_21.pth'))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Move model to GPU if available\n",
        "import torch\n",
        "print(\"\\nPyTorch version:\", torch.__version__)\n",
        "print(\"CUDA available:\", torch.cuda.is_available())\n",
        "if torch.cuda.is_available():\n",
        "    print(\"CUDA version:\", torch.version.cuda)\n",
        "    print(\"GPU device name:\", torch.cuda.get_device_name(0))\n",
        "    print(\"Number of GPUs:\", torch.cuda.device_count())\n",
        "\n",
        "# GPU Memory management functions\n",
        "def get_gpu_memory():\n",
        "    \"\"\"Print GPU memory usage\"\"\"\n",
        "    if torch.cuda.is_available():\n",
        "        print(f\"Allocated: {torch.cuda.memory_allocated(0)/1024**2:.2f}MB\")\n",
        "        print(f\"Cached: {torch.cuda.memory_reserved(0)/1024**2:.2f}MB\")\n",
        "\n",
        "def clear_gpu_memory():\n",
        "    \"\"\"Clear GPU memory\"\"\"\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.empty_cache()\n",
        "        torch.cuda.ipc_collect()\n",
        "\n",
        "# Device selection function\n",
        "def get_device():\n",
        "    \"\"\"Get appropriate device\"\"\"\n",
        "    if torch.cuda.is_available():\n",
        "        device = torch.device(\"cuda\")\n",
        "        print(f\"Using GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    else:\n",
        "        device = torch.device(\"cpu\")\n",
        "        print(\"Using CPU\")\n",
        "    return device\n",
        "\n",
        "# Get the device\n",
        "device = get_device()\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "id": "SsM_IvU5djW3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Image transforms (NO-AUGMENTATION)\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])"
      ],
      "metadata": {
        "id": "M75ZP__BdqAa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Initialize lists for pseudo-labels\n",
        "pseudo_labels = []\n",
        "predictions = []\n",
        "\n",
        "# Set the model to evaluation mode (useful for inference)\n",
        "model.eval()\n",
        "# count = 0\n",
        "with torch.no_grad():\n",
        "    for img_name in tqdm(test_images, desc=\"Testing images\", unit=\"image\"):\n",
        "        img_path = os.path.join(test_images_folder, img_name)\n",
        "        image = Image.open(img_path).convert(\"RGB\")\n",
        "        image = transform_test(image).unsqueeze(0).to(device)  # Add batch dimension\n",
        "\n",
        "        outputs = model(image)  # Get model outputs\n",
        "        prob = torch.softmax(outputs, dim=1)  # Convert to probabilities\n",
        "        confidence, predicted = torch.max(prob, 1)\n",
        "\n",
        "        predictions.append(predicted.item())\n",
        "        pseudo_labels.append(img_name)  # Collect pseudo-labels\n",
        "\n",
        "# Create a DataFrame for pseudo-labels\n",
        "df_pseudo = pd.DataFrame({'image': pseudo_labels, 'id': predictions})\n",
        "\n",
        "print(df_pseudo)\n",
        "\n",
        "df_pseudo.to_csv('/content/report.csv', index=False)"
      ],
      "metadata": {
        "id": "n5XE_36bdb5R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6017453c-e6a1-4f99-ad80-f8f3caa1522e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Testing images: 100%|██████████| 8213/8213 [04:10<00:00, 32.72image/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "          image   id\n",
            "0     34748.jpg  109\n",
            "1     35429.jpg   17\n",
            "2     40460.jpg   24\n",
            "3     36287.jpg   39\n",
            "4     36975.jpg   33\n",
            "...         ...  ...\n",
            "8208  35186.jpg    6\n",
            "8209  35202.jpg    8\n",
            "8210  34167.jpg    7\n",
            "8211  40431.jpg   13\n",
            "8212  34657.jpg   12\n",
            "\n",
            "[8213 rows x 2 columns]\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    },
    "colab": {
      "provenance": []
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "edfc4812cd6242929a5433e7731c46b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c50985fdddab41508f47f699cea57037",
              "IPY_MODEL_434d8e66323143478478bda6ae89e55c",
              "IPY_MODEL_f1019ab57b7a4dca841097afc0b4a73a"
            ],
            "layout": "IPY_MODEL_6abb5abb962f42fba057357c756daef9"
          }
        },
        "c50985fdddab41508f47f699cea57037": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_038136ab1a3f438892c2e6e0653b7e0b",
            "placeholder": "​",
            "style": "IPY_MODEL_2f5cf0cbcbb9496396ee2cb6ccc3ef05",
            "value": "model.safetensors: 100%"
          }
        },
        "434d8e66323143478478bda6ae89e55c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d74ad149740d4ed1be92ff373cfd28fe",
            "max": 800582904,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b474d5394c0545939a1ddfe9392d6f20",
            "value": 800582904
          }
        },
        "f1019ab57b7a4dca841097afc0b4a73a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d620f793c980479aa1ebf8086f462c45",
            "placeholder": "​",
            "style": "IPY_MODEL_c0ece548205f476fa7202472ef11e74b",
            "value": " 801M/801M [00:09&lt;00:00, 97.7MB/s]"
          }
        },
        "6abb5abb962f42fba057357c756daef9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "038136ab1a3f438892c2e6e0653b7e0b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2f5cf0cbcbb9496396ee2cb6ccc3ef05": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d74ad149740d4ed1be92ff373cfd28fe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b474d5394c0545939a1ddfe9392d6f20": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d620f793c980479aa1ebf8086f462c45": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c0ece548205f476fa7202472ef11e74b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}